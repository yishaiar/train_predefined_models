{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "from evaluation_functions import *\n",
    "from torchvision_models import *\n",
    "\n",
    "import pickle \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import mlflow\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "torch.cuda.empty_cache()\n",
    "torch.set_float32_matmul_precision('medium')#gpu precision\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# ----------------\n",
    "isSmallDataset = True\n",
    "testing = True\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "add = os.getcwd()+'/.data'\n",
    "def getData(add,download=False):\n",
    "    train_set = torchvision.datasets.CIFAR100(root = add, train = True, download = download, transform = torchvision.transforms.ToTensor())\n",
    "    val_set = torchvision.datasets.CIFAR100(root = add, train = False, download = download, transform = torchvision.transforms.ToTensor())\n",
    "    return train_set,val_set\n",
    "    \n",
    "try:\n",
    "    train_set,val_set = getData(add,download=False)\n",
    "except:\n",
    "    train_set,val_set = getData(add,download=True)\n",
    "\n",
    "# # subsample\n",
    "class_to_idx = train_set.class_to_idx\n",
    "# train_set = torch.utils.data.Subset(train_set,torch.arange(100)) if isSmallDataset else train_set\n",
    "# val_set = torch.utils.data.Subset(val_set,torch.arange(100)) if isSmallDataset else val_set\n",
    "\n",
    "\n",
    "# y=[]\n",
    "# for [xx1,yy1],[xx2,yy2] in zip(train_set,val_set):\n",
    "#     y+=[yy1,yy2]\n",
    "# y = np.unique(y)\n",
    "num_classes = len(class_to_idx)\n",
    "class_names ={}\n",
    "class_transform = {}\n",
    "for key,value in class_to_idx.items():\n",
    "    class_names[value] = key\n",
    "    class_transform[value] = value# if classe are not numbered from 0 to n-1 consecutively\n",
    "    # print(key,value)\n",
    "class_info = (class_names,class_transform)\n",
    "# class_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2**5\n",
    "num_workers= 4 if device.type != 'cuda:0' else 16\n",
    "DataLoaderParams = {'num_workers': num_workers, 'drop_last':True, 'persistent_workers':True,}\n",
    "\n",
    "sampler = None\n",
    "Datasets = {\n",
    "    'train': train_set,\n",
    "    'val': val_set,\n",
    "    'DataLoaderParams': DataLoaderParams,\n",
    "    'sampler': sampler,\n",
    "    'class_info':class_info,\n",
    "    'isSmallDataset': isSmallDataset\n",
    "}\n",
    "dataloaders = {\n",
    "                'train': DataLoader(Datasets['train'],**Datasets['DataLoaderParams'],sampler=Datasets['sampler'],batch_size=batch_size),\n",
    "                'val': DataLoader(Datasets['val'],**Datasets['DataLoaderParams'],shuffle = False,batch_size=batch_size)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y =[]\n",
    "for i ,[_,yy] in enumerate(dataloaders['train']):\n",
    "    y += yy.tolist()\n",
    "    # print(f'batch {type(yy.tolist())} loaded')\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0 loaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x25728da8b10>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i ,[xx,yy] in enumerate(dataloaders['train']):\n",
    "    print(f'batch {i} loaded')\n",
    "    # if i>0:\n",
    "    break\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(5,5))\n",
    "im = ax.imshow(xx[0,1,:,:])\n",
    "# im = ax.imshow(xx[0,:,:,:],cmap='gray')\n",
    "fig.colorbar(im,ax=ax,orientation='horizontal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mlflow - connect to experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///c:/Users/yili0901/Documents/GitHub/train_predefined_models/mlruns/616396183234793699', creation_time=1701618008066, experiment_id='616396183234793699', last_update_time=1701618008066, lifecycle_stage='active', name='torchvision_models', tags={}>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_name = 'torchvision_models'\n",
    "mlflow.set_experiment(experiment_name)\n",
    "# mlflow.set_tracking_uri('file:/home/riccardo/mlruns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_name': 'resnet18', 'lr': 0.1, 'scheduler_step': None, 'optimizer': 'Adam', 'epochs': 1, 'batch_size': 4, 'weights': None, 'criterion': 'CrossEntropyLoss'}\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "testing = True\n",
    "if testing:\n",
    "    hparams = {\n",
    "        'model_name': ['resnet18'],\n",
    "        'lr': [0.1],\n",
    "        'scheduler_step': [None],\n",
    "        'optimizer': ['Adam'],\n",
    "        'epochs': [1],\n",
    "        'batch_size': [2**2],\n",
    "        'weights': [None],\n",
    "        'criterion': ['CrossEntropyLoss'],\n",
    "    }\n",
    "else:\n",
    "\n",
    "    hparams = {\n",
    "        'model_name': ['resnet18','resnet50'],\n",
    "        'lr': [0.1,0.01],\n",
    "        'scheduler_step': [None,30],\n",
    "        'optimizer': ['Adam','SGD'],\n",
    "        'epochs': [1],\n",
    "        'batch_size': [2**7],\n",
    "        'weights': [None],\n",
    "        'criterion': ['CrossEntropyLoss'],\n",
    "    }\n",
    "hparams = calc_hparams(hparams, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Initiating resnet18_Adam_CrossEntropyLoss_0.01_4_scheduler_step_None_weights_None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "2023/12/03 18:59:17 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "The git executable must be specified in one of the following ways:\n",
      "    - be included in your $PATH\n",
      "    - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "    - explicitly set via git.refresh()\n",
      "\n",
      "All git commands will error until this is rectified.\n",
      "\n",
      "This initial warning can be silenced or aggravated in the future by setting the\n",
      "$GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "    - quiet|q|silence|s|none|n|0: for no warning or exception\n",
      "    - warn|w|warning|1: for a printed warning\n",
      "    - error|e|raise|r|2: for a raised exception\n",
      "\n",
      "Example:\n",
      "    export GIT_PYTHON_REFRESH=quiet\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | back_bone  | ResNet             | 11.2 M\n",
      "1 | criterion_ | CrossEntropyLoss   | 0     \n",
      "2 | train_acc  | MulticlassAccuracy | 0     \n",
      "3 | val_acc    | MulticlassAccuracy | 0     \n",
      "4 | test_acc   | MulticlassAccuracy | 0     \n",
      "--------------------------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.710    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Target 49 is out of bounds.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\yili0901\\Documents\\GitHub\\train_predefined_models\\_run_model.ipynb Cell 10\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yili0901/Documents/GitHub/train_predefined_models/_run_model.ipynb#X11sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m model,trainer             \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yili0901/Documents/GitHub/train_predefined_models/_run_model.ipynb#X11sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m mlflow\u001b[39m.\u001b[39mend_run()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/yili0901/Documents/GitHub/train_predefined_models/_run_model.ipynb#X11sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m train_model(Datasets, device, epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,num_classes\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m,lr\u001b[39m=\u001b[39;49m\u001b[39m0.01\u001b[39;49m,optimizer \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mAdam\u001b[39;49m\u001b[39m'\u001b[39;49m,model_name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mresnet18\u001b[39;49m\u001b[39m'\u001b[39;49m, weights\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39m2\u001b[39;49m, criterion\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mCrossEntropyLoss\u001b[39;49m\u001b[39m'\u001b[39;49m,scheduler_step\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n",
      "\u001b[1;32mc:\\Users\\yili0901\\Documents\\GitHub\\train_predefined_models\\_run_model.ipynb Cell 10\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yili0901/Documents/GitHub/train_predefined_models/_run_model.ipynb#X11sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m mlflow\u001b[39m.\u001b[39mpytorch\u001b[39m.\u001b[39mautolog(registered_model_name\u001b[39m=\u001b[39mmodel_name,silent\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\u001b[39m#log all parameters - works only with pytorch lightning\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yili0901/Documents/GitHub/train_predefined_models/_run_model.ipynb#X11sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m mlflow\u001b[39m.\u001b[39mlog_params({\u001b[39m'\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m'\u001b[39m: model_name,\u001b[39m'\u001b[39m\u001b[39mbatch_size\u001b[39m\u001b[39m'\u001b[39m: batch_size,\u001b[39m'\u001b[39m\u001b[39mpretrain_weights\u001b[39m\u001b[39m'\u001b[39m: weights,\u001b[39m'\u001b[39m\u001b[39mcriterion\u001b[39m\u001b[39m'\u001b[39m: criterion,\u001b[39m'\u001b[39m\u001b[39moptimizer\u001b[39m\u001b[39m'\u001b[39m:optimizer, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yili0901/Documents/GitHub/train_predefined_models/_run_model.ipynb#X11sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39mepochs\u001b[39m\u001b[39m'\u001b[39m: epochs,\u001b[39m'\u001b[39m\u001b[39mscheduler_step\u001b[39m\u001b[39m'\u001b[39m: scheduler_step})\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/yili0901/Documents/GitHub/train_predefined_models/_run_model.ipynb#X11sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(model, train_dataloaders \u001b[39m=\u001b[39;49m dataloaders[\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m], val_dataloaders \u001b[39m=\u001b[39;49mdataloaders[\u001b[39m'\u001b[39;49m\u001b[39mval\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yili0901/Documents/GitHub/train_predefined_models/_run_model.ipynb#X11sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mprint\u001b[39m (\u001b[39m'\u001b[39m\u001b[39mTraining complete\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yili0901/Documents/GitHub/train_predefined_models/_run_model.ipynb#X11sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39m# ----------------------------------\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\yili0901\\Documents\\GitHub\\train_predefined_models\\.venv\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:571\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    569\u001b[0m     patch_function\u001b[39m.\u001b[39mcall(call_original, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    570\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 571\u001b[0m     patch_function(call_original, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    573\u001b[0m session\u001b[39m.\u001b[39mstate \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msucceeded\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    575\u001b[0m try_log_autologging_event(\n\u001b[0;32m    576\u001b[0m     AutologgingEventLogger\u001b[39m.\u001b[39mget_logger()\u001b[39m.\u001b[39mlog_patch_function_success,\n\u001b[0;32m    577\u001b[0m     session,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    581\u001b[0m     kwargs,\n\u001b[0;32m    582\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\yili0901\\Documents\\GitHub\\train_predefined_models\\.venv\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:250\u001b[0m, in \u001b[0;36mwith_managed_run.<locals>.patch_with_managed_run\u001b[1;34m(original, *args, **kwargs)\u001b[0m\n\u001b[0;32m    247\u001b[0m     managed_run \u001b[39m=\u001b[39m create_managed_run()\n\u001b[0;32m    249\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 250\u001b[0m     result \u001b[39m=\u001b[39m patch_function(original, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    251\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mException\u001b[39;00m, \u001b[39mKeyboardInterrupt\u001b[39;00m):\n\u001b[0;32m    252\u001b[0m     \u001b[39m# In addition to standard Python exceptions, handle keyboard interrupts to ensure\u001b[39;00m\n\u001b[0;32m    253\u001b[0m     \u001b[39m# that runs are terminated if a user prematurely interrupts training execution\u001b[39;00m\n\u001b[0;32m    254\u001b[0m     \u001b[39m# (e.g. via sigint / ctrl-c)\u001b[39;00m\n\u001b[0;32m    255\u001b[0m     \u001b[39mif\u001b[39;00m managed_run:\n",
      "File \u001b[1;32mc:\\Users\\yili0901\\Documents\\GitHub\\train_predefined_models\\.venv\\Lib\\site-packages\\mlflow\\pytorch\\_lightning_autolog.py:386\u001b[0m, in \u001b[0;36mpatched_fit\u001b[1;34m(original, self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    378\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m [\n\u001b[0;32m    379\u001b[0m         __MLflowPLCallback(\n\u001b[0;32m    380\u001b[0m             client, metrics_logger, run_id, log_models, log_every_n_epoch, log_every_n_step\n\u001b[0;32m    381\u001b[0m         )\n\u001b[0;32m    382\u001b[0m     ]\n\u001b[0;32m    384\u001b[0m client\u001b[39m.\u001b[39mflush(synchronous\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m--> 386\u001b[0m result \u001b[39m=\u001b[39m original(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    388\u001b[0m \u001b[39mif\u001b[39;00m early_stop_callback \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    389\u001b[0m     _log_early_stop_metrics(early_stop_callback, client, run_id)\n",
      "File \u001b[1;32mc:\\Users\\yili0901\\Documents\\GitHub\\train_predefined_models\\.venv\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:552\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original\u001b[1;34m(*og_args, **og_kwargs)\u001b[0m\n\u001b[0;32m    549\u001b[0m         original_result \u001b[39m=\u001b[39m original(\u001b[39m*\u001b[39m_og_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m_og_kwargs)\n\u001b[0;32m    550\u001b[0m         \u001b[39mreturn\u001b[39;00m original_result\n\u001b[1;32m--> 552\u001b[0m \u001b[39mreturn\u001b[39;00m call_original_fn_with_event_logging(_original_fn, og_args, og_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\yili0901\\Documents\\GitHub\\train_predefined_models\\.venv\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:487\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original_fn_with_event_logging\u001b[1;34m(original_fn, og_args, og_kwargs)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    479\u001b[0m     try_log_autologging_event(\n\u001b[0;32m    480\u001b[0m         AutologgingEventLogger\u001b[39m.\u001b[39mget_logger()\u001b[39m.\u001b[39mlog_original_function_start,\n\u001b[0;32m    481\u001b[0m         session,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         og_kwargs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m     original_fn_result \u001b[39m=\u001b[39m original_fn(\u001b[39m*\u001b[39;49mog_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mog_kwargs)\n\u001b[0;32m    489\u001b[0m     try_log_autologging_event(\n\u001b[0;32m    490\u001b[0m         AutologgingEventLogger\u001b[39m.\u001b[39mget_logger()\u001b[39m.\u001b[39mlog_original_function_success,\n\u001b[0;32m    491\u001b[0m         session,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    495\u001b[0m         og_kwargs,\n\u001b[0;32m    496\u001b[0m     )\n\u001b[0;32m    497\u001b[0m     \u001b[39mreturn\u001b[39;00m original_fn_result\n",
      "File \u001b[1;32mc:\\Users\\yili0901\\Documents\\GitHub\\train_predefined_models\\.venv\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:549\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original.<locals>._original_fn\u001b[1;34m(*_og_args, **_og_kwargs)\u001b[0m\n\u001b[0;32m    541\u001b[0m \u001b[39m# Show all non-MLflow warnings as normal (i.e. not as event logs)\u001b[39;00m\n\u001b[0;32m    542\u001b[0m \u001b[39m# during original function execution, even if silent mode is enabled\u001b[39;00m\n\u001b[0;32m    543\u001b[0m \u001b[39m# (`silent=True`), since these warnings originate from the ML framework\u001b[39;00m\n\u001b[0;32m    544\u001b[0m \u001b[39m# or one of its dependencies and are likely relevant to the caller\u001b[39;00m\n\u001b[0;32m    545\u001b[0m \u001b[39mwith\u001b[39;00m set_non_mlflow_warnings_behavior_for_current_thread(\n\u001b[0;32m    546\u001b[0m     disable_warnings\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    547\u001b[0m     reroute_warnings\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    548\u001b[0m ):\n\u001b[1;32m--> 549\u001b[0m     original_result \u001b[39m=\u001b[39m original(\u001b[39m*\u001b[39;49m_og_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m_og_kwargs)\n\u001b[0;32m    550\u001b[0m     \u001b[39mreturn\u001b[39;00m original_result\n",
      "File \u001b[1;32mc:\\Users\\yili0901\\Documents\\GitHub\\train_predefined_models\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:545\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    543\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstatus \u001b[39m=\u001b[39m TrainerStatus\u001b[39m.\u001b[39mRUNNING\n\u001b[0;32m    544\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m--> 545\u001b[0m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[0;32m    546\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[0;32m    547\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\yili0901\\Documents\\GitHub\\train_predefined_models\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     43\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m---> 44\u001b[0m     \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     46\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n\u001b[0;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[1;32mc:\\Users\\yili0901\\Documents\\GitHub\\train_predefined_models\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:581\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    574\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    575\u001b[0m ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_select_ckpt_path(\n\u001b[0;32m    576\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn,\n\u001b[0;32m    577\u001b[0m     ckpt_path,\n\u001b[0;32m    578\u001b[0m     model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    579\u001b[0m     model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    580\u001b[0m )\n\u001b[1;32m--> 581\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49mckpt_path)\n\u001b[0;32m    583\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[0;32m    584\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\yili0901\\Documents\\GitHub\\train_predefined_models\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:990\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_signal_connector\u001b[39m.\u001b[39mregister_signal_handlers()\n\u001b[0;32m    987\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m    988\u001b[0m \u001b[39m# RUN THE TRAINER\u001b[39;00m\n\u001b[0;32m    989\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m--> 990\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_stage()\n\u001b[0;32m    992\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m    993\u001b[0m \u001b[39m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[0;32m    994\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m    995\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: trainer tearing down\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\yili0901\\Documents\\GitHub\\train_predefined_models\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1034\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1032\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining:\n\u001b[0;32m   1033\u001b[0m     \u001b[39mwith\u001b[39;00m isolate_rng():\n\u001b[1;32m-> 1034\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_sanity_check()\n\u001b[0;32m   1035\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mset_detect_anomaly(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_detect_anomaly):\n\u001b[0;32m   1036\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_loop\u001b[39m.\u001b[39mrun()\n",
      "File \u001b[1;32mc:\\Users\\yili0901\\Documents\\GitHub\\train_predefined_models\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1063\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1060\u001b[0m call\u001b[39m.\u001b[39m_call_callback_hooks(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mon_sanity_check_start\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1062\u001b[0m \u001b[39m# run eval step\u001b[39;00m\n\u001b[1;32m-> 1063\u001b[0m val_loop\u001b[39m.\u001b[39;49mrun()\n\u001b[0;32m   1065\u001b[0m call\u001b[39m.\u001b[39m_call_callback_hooks(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mon_sanity_check_end\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1067\u001b[0m \u001b[39m# reset logger connector\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\yili0901\\Documents\\GitHub\\train_predefined_models\\.venv\\Lib\\site-packages\\pytorch_lightning\\loops\\utilities.py:181\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m     context_manager \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mno_grad\n\u001b[0;32m    180\u001b[0m \u001b[39mwith\u001b[39;00m context_manager():\n\u001b[1;32m--> 181\u001b[0m     \u001b[39mreturn\u001b[39;00m loop_run(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\yili0901\\Documents\\GitHub\\train_predefined_models\\.venv\\Lib\\site-packages\\pytorch_lightning\\loops\\evaluation_loop.py:134\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    132\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mis_last_batch \u001b[39m=\u001b[39m data_fetcher\u001b[39m.\u001b[39mdone\n\u001b[0;32m    133\u001b[0m     \u001b[39m# run step hooks\u001b[39;00m\n\u001b[1;32m--> 134\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)\n\u001b[0;32m    135\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[0;32m    136\u001b[0m     \u001b[39m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[39;00m\n\u001b[0;32m    137\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\yili0901\\Documents\\GitHub\\train_predefined_models\\.venv\\Lib\\site-packages\\pytorch_lightning\\loops\\evaluation_loop.py:391\u001b[0m, in \u001b[0;36m_EvaluationLoop._evaluation_step\u001b[1;34m(self, batch, batch_idx, dataloader_idx, dataloader_iter)\u001b[0m\n\u001b[0;32m    385\u001b[0m hook_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtest_step\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mtesting \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mvalidation_step\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    386\u001b[0m step_args \u001b[39m=\u001b[39m (\n\u001b[0;32m    387\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_step_args_from_hook_kwargs(hook_kwargs, hook_name)\n\u001b[0;32m    388\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m using_dataloader_iter\n\u001b[0;32m    389\u001b[0m     \u001b[39melse\u001b[39;00m (dataloader_iter,)\n\u001b[0;32m    390\u001b[0m )\n\u001b[1;32m--> 391\u001b[0m output \u001b[39m=\u001b[39m call\u001b[39m.\u001b[39;49m_call_strategy_hook(trainer, hook_name, \u001b[39m*\u001b[39;49mstep_args)\n\u001b[0;32m    393\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mincrement_processed()\n\u001b[0;32m    395\u001b[0m \u001b[39mif\u001b[39;00m using_dataloader_iter:\n\u001b[0;32m    396\u001b[0m     \u001b[39m# update the hook kwargs now that the step method might have consumed the iterator\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\yili0901\\Documents\\GitHub\\train_predefined_models\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:309\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[1;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[0;32m    306\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \u001b[39mwith\u001b[39;00m trainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[Strategy]\u001b[39m\u001b[39m{\u001b[39;00mtrainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 309\u001b[0m     output \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    311\u001b[0m \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[0;32m    312\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n",
      "File \u001b[1;32mc:\\Users\\yili0901\\Documents\\GitHub\\train_predefined_models\\.venv\\Lib\\site-packages\\pytorch_lightning\\strategies\\strategy.py:403\u001b[0m, in \u001b[0;36mStrategy.validation_step\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module:\n\u001b[0;32m    402\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_redirection(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module, \u001b[39m\"\u001b[39m\u001b[39mvalidation_step\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 403\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlightning_module\u001b[39m.\u001b[39;49mvalidation_step(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\yili0901\\Documents\\GitHub\\train_predefined_models\\torchvision_models.py:68\u001b[0m, in \u001b[0;36mget_model_lightning.validation_step\u001b[1;34m(self, batch, batch_idx)\u001b[0m\n\u001b[0;32m     66\u001b[0m x, y \u001b[39m=\u001b[39m batch\n\u001b[0;32m     67\u001b[0m logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m(x)\u001b[39m#outputs of last fully connected layer before softmax\u001b[39;00m\n\u001b[1;32m---> 68\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcriterion(logits, y)\u001b[39m#CrossEntropyLoss\u001b[39;00m\n\u001b[0;32m     69\u001b[0m preds \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39margmax(logits, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m#get the index of the max log-probability; equivalent to _,preds = torch.max(logits, dim=1)\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog(\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m, loss, prog_bar\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\yili0901\\Documents\\GitHub\\train_predefined_models\\torchvision_models.py:38\u001b[0m, in \u001b[0;36mget_model_lightning.criterion\u001b[1;34m(self, logits, y)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcriterion\u001b[39m(\u001b[39mself\u001b[39m, logits, y): \n\u001b[1;32m---> 38\u001b[0m       \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcriterion_(logits, y\u001b[39m.\u001b[39;49mlong())\n",
      "File \u001b[1;32mc:\\Users\\yili0901\\Documents\\GitHub\\train_predefined_models\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\yili0901\\Documents\\GitHub\\train_predefined_models\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:1174\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1173\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m-> 1174\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mcross_entropy(\u001b[39minput\u001b[39;49m, target, weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[0;32m   1175\u001b[0m                            ignore_index\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mignore_index, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction,\n\u001b[0;32m   1176\u001b[0m                            label_smoothing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabel_smoothing)\n",
      "File \u001b[1;32mc:\\Users\\yili0901\\Documents\\GitHub\\train_predefined_models\\.venv\\Lib\\site-packages\\torch\\nn\\functional.py:3029\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3027\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   3028\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3029\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mcross_entropy_loss(\u001b[39minput\u001b[39;49m, target, weight, _Reduction\u001b[39m.\u001b[39;49mget_enum(reduction), ignore_index, label_smoothing)\n",
      "\u001b[1;31mIndexError\u001b[0m: Target 49 is out of bounds."
     ]
    }
   ],
   "source": [
    "def train_model(Datasets, device, epochs,num_classes=2,lr=0.01,optimizer = 'Adam',model_name='resnet18', weights=None, batch_size=2**2, criterion='CrossEntropyLoss',scheduler_step=None):\n",
    "    run_name = f'{model_name}_{optimizer}_{criterion}_{lr}_{batch_size}_scheduler_step_{scheduler_step}_weights_{weights}'\n",
    "    print ('-'*150)\n",
    "\n",
    "    print(f'Initiating {run_name}')\n",
    "    model = get_model_lightning(model_name,num_classes, optimizer, lr, weights, criterion, scheduler_step).to(device)\n",
    "    # create dataloaders from predefined datasets\n",
    "    dataloaders = {\n",
    "                'train': DataLoader(Datasets['train'],**Datasets['DataLoaderParams'],sampler=Datasets['sampler'],batch_size=batch_size),\n",
    "                'val': DataLoader(Datasets['val'],**Datasets['DataLoaderParams'],shuffle = False,batch_size=batch_size)\n",
    "                }\n",
    "    pl.seed_everything(42,workers=True)\n",
    "    pl_accelerator = device.type if device.type != 'cuda:0' else 'gpu'#'auto' can be used for automatic choice\n",
    "    trainer = pl.Trainer(max_epochs=epochs, log_every_n_steps=1,enable_checkpointing=False,precision='bf16-mixed',\n",
    "                         deterministic=True,accelerator=pl_accelerator, devices='auto',#devices='0,1' for multiple gpus\n",
    "                         limit_train_batches=0.05,limit_val_batches=0.05,limit_test_batches=0.05,)#percentage of dataset batches used in epoch\n",
    "\n",
    "    print ('Training start')  \n",
    "    mlflow.start_run(run_name=run_name)\n",
    "    mlflow.pytorch.autolog(registered_model_name=model_name,silent=False)#log all parameters - works only with pytorch lightning\n",
    "    mlflow.log_params({'model': model_name,'batch_size': batch_size,'pretrain_weights': weights,'criterion': criterion,'optimizer':optimizer, \n",
    "                       'epochs': epochs,'scheduler_step': scheduler_step})\n",
    "    trainer.fit(model, train_dataloaders = dataloaders['train'], val_dataloaders =dataloaders['val'])\n",
    "    print ('Training complete')\n",
    "    # ----------------------------------\n",
    "    print('Predicting (test) start')\n",
    "    y_pred_test,y_true_test = seperate_predictions(trainer.predict(model,dataloaders['val']))#y_pred_test,y_true_test are recieved by batch of both needs to be restructured\n",
    "    test_metrics = evaluate_metrics(y_true_test,y_pred_test)\n",
    "    print(test_metrics)\n",
    "\n",
    "    # calculate confusion matrix,classification report \n",
    "    eval_metric_figs(y_pred_test,y_true_test,num_classes,class_names=class_info[0],class_transform=class_info[1], save=True,folder_name=run_name)   \n",
    "    \n",
    "    mlflow.log_metrics(test_metrics)\n",
    "    mlflow.end_run() \n",
    "    return model,trainer             \n",
    "\n",
    "mlflow.end_run()\n",
    "train_model(Datasets, device, epochs=1,num_classes=2,lr=0.01,optimizer = 'Adam',model_name='resnet18', weights=None, batch_size=2**2, criterion='CrossEntropyLoss',scheduler_step=None)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "{'model_name': 'resnet18', 'lr': 0.1, 'scheduler_step': None, 'optimizer': 'Adam', 'epochs': 1, 'batch_size': 4, 'weights': None, 'criterion': 'CrossEntropyLoss'}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "train_model() got multiple values for argument 'epochs'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\yili0901\\Documents\\GitHub\\train_predefined_models\\_run_model.ipynb Cell 10\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/yili0901/Documents/GitHub/train_predefined_models/_run_model.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m\u001b[39m*\u001b[39m\u001b[39m150\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/yili0901/Documents/GitHub/train_predefined_models/_run_model.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(p)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/yili0901/Documents/GitHub/train_predefined_models/_run_model.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m model,trainer \u001b[39m=\u001b[39m train_model(Datasets\u001b[39m.\u001b[39;49mcopy(), device, num_classes, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mp)\n",
      "\u001b[1;31mTypeError\u001b[0m: train_model() got multiple values for argument 'epochs'"
     ]
    }
   ],
   "source": [
    "for p in hparams:\n",
    "    print('-'*150)\n",
    "    print('-'*150)\n",
    "    print(p)\n",
    "    \n",
    "    model,trainer = train_model(Datasets.copy(), device, num_classes, **p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
